import requests
from bs4 import BeautifulSoup
import lxml
import celery
import xmltodict
from time import sleep

MAIN_PAGE = 'https://zakupki.gov.ru/'
headers = {
    "Accept":'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
    'UserAgent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36'
}

def main():
    for i in range(1, 3):
        print('======================================================================================')
        print(f'Страница {i}:')
        print('--------------------------------------------------------------------------------------')        
        src = requests.get(
            f'https://zakupki.gov.ru/epz/order/extendedsearch/results.html?fz44=on&pageNumber={i}', 
            headers=headers
            )
        soup = BeautifulSoup(src.content, 'lxml').find_all('a')
        for i in soup:
            link = i.get('href')
            if link is not None:
                if 'printForm' in link and 'view' in link and 'regNumber' in link:                    
                    get_xml = requests.get(MAIN_PAGE + link.replace('view', 'viewXml')).text  #получаем XML страницу
                    obj = BeautifulSoup(get_xml, 'xml')
                    date = obj.find_all('publishDTInEIS') 
                    printform = obj.find_all('printFormInfo')    
                    print(printform[0].text, date[0].text)
                    sleep(1)
        print('======================================================================================')   
             
        sleep(5) # задержка для избежания блокировки скрипта


# publishDTInEIS

if __name__ == '__main__':
    main()
   
